{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parser import OpenCorporaParser\n",
    "from artm import ARTM\n",
    "from tools import get_pointwise_mutual_information\n",
    "import numpy as np\n",
    "import scipy.sparse as sparse\n",
    "from combined_smoothing_sparsing_regularizer import CombinedSmoothingSparsingRegularizer\n",
    "from covariance_docs_regularizer import CovarianceDocsRegularizer\n",
    "from covariance_topics_regularizer import CovarianceTopicsRegularizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_corpora_parser = OpenCorporaParser()\n",
    "\n",
    "doc_term_matr, vocabulary, year, topic, close_word_pairs = open_corpora_parser.parse_open_corpora(\n",
    "    path_to_corpus='annot.opcorpora.no_ambig.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words_list(vocabulary):\n",
    "    return list(sorted(vocabulary, key=lambda word: vocabulary[word]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_in_doc_freqs = doc_term_matr.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm = np.random.permutation(word_in_doc_freqs.shape[1])\n",
    "word_in_doc_freqs_hold_out = sparse.dok_matrix(word_in_doc_freqs[:, perm[:int(len(perm)/10)]])\n",
    "word_in_doc_freqs_train = sparse.dok_matrix(word_in_doc_freqs[:, perm[int(len(perm)/10):]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_count = word_in_doc_freqs.shape[0]\n",
    "docs_count = word_in_doc_freqs_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter#1: loglike=-232112.48143368118\n",
      "iter#2: loglike=-230232.8404892832\n",
      "iter#3: loglike=-227362.27818222516\n",
      "iter#4: loglike=-222613.65348712401\n",
      "iter#5: loglike=-215438.47972231676\n",
      "iter#6: loglike=-206765.97311331515\n",
      "iter#7: loglike=-198582.00317570867\n",
      "iter#8: loglike=-192135.64972847133\n",
      "iter#9: loglike=-187457.68543131973\n",
      "iter#10: loglike=-184091.1059478081\n",
      "iter#11: loglike=-181599.7854908576\n",
      "iter#12: loglike=-179691.974017075\n",
      "iter#13: loglike=-178188.9154804567\n",
      "iter#14: loglike=-176971.79742480125\n",
      "iter#15: loglike=-175970.21378539843\n",
      "iter#16: loglike=-175137.35283748427\n",
      "iter#17: loglike=-174431.24873664175\n",
      "iter#18: loglike=-173827.72378696981\n",
      "iter#19: loglike=-173310.64079053563\n",
      "iter#20: loglike=-172861.14891889793\n"
     ]
    }
   ],
   "source": [
    "# baseline\n",
    "\n",
    "topics_count = 100\n",
    "\n",
    "plsa_model = ARTM(topics_count=topics_count, regularizers=[], regularizer_weights=[])\n",
    "\n",
    "#TODO: plot convergence to show that EM is implemented correctly.\n",
    "\n",
    "train_result = plsa_model.train(word_in_doc_freqs=word_in_doc_freqs_train,\n",
    "                                words_list=get_words_list(vocabulary),\n",
    "                                iterations_count=20, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "173.66173726035473"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_result.get_train_perplexity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter#1: loglike=-13577.979193660929\n",
      "iter#2: loglike=-13133.387173448176\n",
      "iter#3: loglike=-12964.22661162221\n",
      "iter#4: loglike=-12886.070168487826\n",
      "iter#5: loglike=-12844.230684617056\n",
      "iter#6: loglike=-12819.189697585627\n",
      "iter#7: loglike=-12802.950746503097\n",
      "iter#8: loglike=-12791.78793750208\n",
      "iter#9: loglike=-12783.725741634493\n",
      "iter#10: loglike=-12777.667438810977\n",
      "iter#11: loglike=-12772.963875395495\n",
      "iter#12: loglike=-12769.216052119104\n",
      "iter#13: loglike=-12766.183871820498\n",
      "iter#14: loglike=-12763.726310228576\n",
      "iter#15: loglike=-12761.74622424324\n",
      "iter#16: loglike=-12760.155389606374\n",
      "iter#17: loglike=-12758.870233945256\n",
      "iter#18: loglike=-12757.820012154401\n",
      "iter#19: loglike=-12756.950285298353\n",
      "iter#20: loglike=-12756.220668710263\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(292.81129219999019, 9421.1232441476968)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_result.get_holdout_perplexity(holdout_word_in_doc_freqs=word_in_doc_freqs_hold_out, iterations_count=20, \n",
    "                                    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_word_pairs_hold_out = np.array(close_word_pairs)[perm[:int(len(perm)/10)]]\n",
    "close_word_pairs_train = np.array(close_word_pairs)[perm[int(len(perm)/10):]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6197615636322461"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pmi = get_pointwise_mutual_information(word_in_doc_freqs_train, close_word_pairs_train)\n",
    "\n",
    "train_result.get_pointwise_mutual_information_metric(pmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47958504916211342"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pmi = get_pointwise_mutual_information(word_in_doc_freqs_hold_out, close_word_pairs_hold_out)\n",
    "\n",
    "train_result.get_pointwise_mutual_information_metric(pmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_docs_matrix = (np.array(topic)[:, None] == np.array(topic)).astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "regularizers = [CombinedSmoothingSparsingRegularizer(beta_0=0.5, alpha_0=0.5, \n",
    "                                                     beta=np.array([1e-4]*words_count), \n",
    "                                                     alpha=np.array([1e-4]*topics_count), \n",
    "                                                     num_topics=topics_count, \n",
    "                                                     num_words=words_count, \n",
    "                                                     num_docs=docs_count, \n",
    "                                                     domain_specific_topics=np.arange(80), \n",
    "                                                     background_topics=np.arange(80, 100)), \n",
    "                CovarianceTopicsRegularizer(tau=1.0, num_topics=topics_count, \n",
    "                                            num_words=words_count, num_docs=docs_count), \n",
    "                CovarianceDocsRegularizer(tau=1.0, num_topics=topics_count, num_words=words_count, \n",
    "                                          num_docs=docs_count, \n",
    "                                          similarity_docs_matrix=similarity_docs_matrix)\n",
    "               ]\n",
    "\n",
    "regularizer_weights = [1e-1, 1e-1, 1e-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter#1: loglike=-232097.57402491051\n",
      "iter#2: loglike=-230210.0123460084\n",
      "iter#3: loglike=-227314.90060808152\n",
      "iter#4: loglike=-222531.0125606625\n",
      "iter#5: loglike=-215292.01246277124\n",
      "iter#6: loglike=-206470.65803747554\n",
      "iter#7: loglike=-198145.3977520377\n",
      "iter#8: loglike=-191663.3660065342\n",
      "iter#9: loglike=-187052.52492047072\n",
      "iter#10: loglike=-183791.55683082246\n",
      "iter#11: loglike=-181413.45129180324\n",
      "iter#12: loglike=-179609.92609994358\n",
      "iter#13: loglike=-178177.45528038283\n",
      "iter#14: loglike=-176998.13499583583\n",
      "iter#15: loglike=-176013.33252167297\n",
      "iter#16: loglike=-175186.8882545553\n",
      "iter#17: loglike=-174483.8637188816\n",
      "iter#18: loglike=-173872.17297806047\n",
      "iter#19: loglike=-173335.2059342725\n",
      "iter#20: loglike=-172861.86549992667\n"
     ]
    }
   ],
   "source": [
    "regularized_model = ARTM(topics_count=topics_count, regularizers=regularizers, \n",
    "                         regularizer_weights=regularizer_weights)\n",
    "\n",
    "#TODO: plot convergence to show that EM is implemented correctly.\n",
    "\n",
    "train_result_reg = plsa_model.train(word_in_doc_freqs=word_in_doc_freqs_train,\n",
    "                                words_list=get_words_list(vocabulary),\n",
    "                                iterations_count=20, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "173.22899871268055"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_result_reg.get_train_perplexity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter#1: loglike=-13571.407282588487\n",
      "iter#2: loglike=-13101.715733512685\n",
      "iter#3: loglike=-12922.302287431212\n",
      "iter#4: loglike=-12838.774707915933\n",
      "iter#5: loglike=-12795.158369479012\n",
      "iter#6: loglike=-12770.654297358804\n",
      "iter#7: loglike=-12755.954379387282\n",
      "iter#8: loglike=-12746.517112510033\n",
      "iter#9: loglike=-12740.087927846322\n",
      "iter#10: loglike=-12735.500001148379\n",
      "iter#11: loglike=-12732.11155544102\n",
      "iter#12: loglike=-12729.545671104857\n",
      "iter#13: loglike=-12727.565083455342\n",
      "iter#14: loglike=-12726.0112674667\n",
      "iter#15: loglike=-12724.7740127897\n",
      "iter#16: loglike=-12723.774874688528\n",
      "iter#17: loglike=-12722.957158098669\n",
      "iter#18: loglike=-12722.279419429737\n",
      "iter#19: loglike=-12721.711087176976\n",
      "iter#20: loglike=-12721.2294177277\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(288.28482982420098, 8965.3214380604659)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_result_reg.get_holdout_perplexity(holdout_word_in_doc_freqs=word_in_doc_freqs_hold_out, iterations_count=20, \n",
    "                                    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmi = get_pointwise_mutual_information(word_in_doc_freqs_train, close_word_pairs_train)\n",
    "\n",
    "train_result_reg.get_pointwise_mutual_information_metric(pmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmi = get_pointwise_mutual_information(word_in_doc_freqs_hold_out, close_word_pairs_hold_out)\n",
    "\n",
    "train_result_reg.get_pointwise_mutual_information_metric(pmi)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
