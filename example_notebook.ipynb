{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import artm\n",
    "from base_regularizer import BaseRegularizer\n",
    "from smoothing_regularizer import SmoothingRegularizer\n",
    "from combined_smoothing_sparsing_regularizer import CombinedSmoothingSparsingRegularizer\n",
    "from covariance_topics_regularizer import CovarianceTopicsRegularizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_word_in_doc_freqs(words_count, docs_count):\n",
    "\n",
    "    density = 0.001\n",
    "    max_freq = 5\n",
    "\n",
    "    word_in_doc_freqs = sparse.dok_matrix((words_count, docs_count), dtype=int)\n",
    "\n",
    "    for i in range(int(density*words_count*docs_count)):\n",
    "\n",
    "        word_index = np.random.choice(words_count)\n",
    "        doc_index = np.random.choice(docs_count)\n",
    "\n",
    "        word_in_doc_freqs[word_index, doc_index] = np.random.choice(max_freq) + 1\n",
    "\n",
    "    return word_in_doc_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ZeroRegularizer(BaseRegularizer):\n",
    "\n",
    "    def __init__(self, words_count, docs_count, topics_count):\n",
    "\n",
    "        self._word_in_topics_probs_grad = np.zeros((words_count, topics_count))\n",
    "        self._topic_in_doc_probs_grad = np.zeros((topics_count, docs_count))\n",
    "\n",
    "    def get_value(self, word_in_topics_probs, topic_in_doc_probs):\n",
    "\n",
    "        return 0.0\n",
    "\n",
    "    def get_gradient(self, word_in_topics_probs, topic_in_doc_probs):\n",
    "\n",
    "        return self._word_in_topics_probs_grad, self._topic_in_doc_probs_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed=0)\n",
    "\n",
    "words_count = 10000\n",
    "docs_count = 100\n",
    "topics_count = 10\n",
    "\n",
    "holdout_docs_count = 10\n",
    "\n",
    "word_in_doc_freqs = generate_word_in_doc_freqs(words_count, docs_count)\n",
    "words_list = np.array([str(i) for i in range(words_count)])\n",
    "\n",
    "zero_regularizer = ZeroRegularizer(words_count, docs_count - holdout_docs_count, topics_count)\n",
    "\n",
    "artm_model = artm.ARTM(topics_count, [zero_regularizer], [1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_word_in_doc_freqs = word_in_doc_freqs[:, :-holdout_docs_count]\n",
    "holdout_word_in_doc_freqs = word_in_doc_freqs[:, -holdout_docs_count:]\n",
    "holdout_word_in_doc_freqs_overfit = train_word_in_doc_freqs[:, -holdout_docs_count:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter#1: loglike=-17407.22636104274\n",
      "iter#2: loglike=-16553.85754382502\n",
      "iter#3: loglike=-15337.18379882692\n",
      "iter#4: loglike=-14122.195581624563\n",
      "iter#5: loglike=-13240.240062229397\n",
      "iter#6: loglike=-12707.388352003167\n",
      "iter#7: loglike=-12423.625911423469\n",
      "iter#8: loglike=-12271.463457269032\n",
      "iter#9: loglike=-12184.984019664067\n",
      "iter#10: loglike=-12133.017414077396\n"
     ]
    }
   ],
   "source": [
    "train_result = artm_model.train(train_word_in_doc_freqs, words_list, iterations_count=10, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train perplexity: 83.50267830167759\n",
      "Hold out perplexity: 3483097210.613652\n",
      "Hold out perplexity (train data leak): 76.9329014289757\n"
     ]
    }
   ],
   "source": [
    "print('Train perplexity: {}'.format(train_result.get_train_perplexity()))\n",
    "\n",
    "# Perplexity is big for a complete random holdout set\n",
    "print('Hold out perplexity: {}'.format(train_result.get_holdout_perplexity(holdout_word_in_doc_freqs,\n",
    "                                                                          iterations_count=10)[1]))\n",
    "\n",
    "# While it's reasonable for training data subset\n",
    "print('Hold out perplexity (train data leak): {}'.format(\n",
    "    train_result.get_holdout_perplexity(holdout_word_in_doc_freqs_overfit, iterations_count=10)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['4545', '1663', '5103', '7726', '4471', '4419', '3863', '7782',\n",
       "        '5666', '2251'],\n",
       "       ['2593', '3877', '7315', '5192', '1725', '8291', '9483', '5878',\n",
       "        '4300', '2467'],\n",
       "       ['2597', '6538', '6781', '7762', '960', '6870', '1562', '6514',\n",
       "        '1609', '4998'],\n",
       "       ['2659', '1004', '2273', '4562', '4331', '6117', '8889', '6216',\n",
       "        '8819', '1099'],\n",
       "       ['1981', '5339', '1401', '9576', '7627', '75', '1440', '2502',\n",
       "        '4573', '7970'],\n",
       "       ['815', '2582', '2010', '876', '1614', '2317', '2257', '77', '6447',\n",
       "        '7526'],\n",
       "       ['3918', '2003', '1610', '8769', '1820', '6769', '2392', '3041',\n",
       "        '6687', '3317'],\n",
       "       ['7444', '7751', '4005', '8837', '8131', '9686', '3012', '8246',\n",
       "        '7318', '4332'],\n",
       "       ['4814', '4690', '3945', '127', '6337', '6273', '8393', '7160',\n",
       "        '4751', '4057'],\n",
       "       ['5703', '8809', '4047', '7434', '493', '8948', '9987', '1851',\n",
       "        '3845', '523']],\n",
       "      dtype='<U4')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_result.get_top_words_in_topics(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smoothing reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "smoothing_regularizer = SmoothingRegularizer(beta_0=0.5, alpha_0=0.5, \n",
    "                                             beta=np.array([1e-4]*words_count), \n",
    "                                             alpha=np.array([1e-4]*topics_count), \n",
    "                                             num_topics=topics_count, \n",
    "                                             num_words=words_count, \n",
    "                                             num_docs=docs_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "artm_model = artm.ARTM(topics_count, [smoothing_regularizer], [1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter#1: loglike=-19482.763378626827\n",
      "iter#2: loglike=-18520.359458412888\n",
      "iter#3: loglike=-17228.643654167827\n",
      "iter#4: loglike=-15972.047206415315\n",
      "iter#5: loglike=-15031.23507602721\n",
      "iter#6: loglike=-14380.564561543266\n",
      "iter#7: loglike=-13968.665122778333\n",
      "iter#8: loglike=-13763.744803667347\n",
      "iter#9: loglike=-13676.81786171648\n",
      "iter#10: loglike=-13634.93516738866\n"
     ]
    }
   ],
   "source": [
    "train_result = artm_model.train(word_in_doc_freqs, words_list, iterations_count=10, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining smooth and sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sparse_smooth_reg = CombinedSmoothingSparsingRegularizer(beta_0=0.5, alpha_0=0.5, \n",
    "                                                         beta=np.array([1e-4]*words_count), \n",
    "                                                         alpha=np.array([1e-4]*topics_count), \n",
    "                                                         num_topics=topics_count, \n",
    "                                                         num_words=words_count, \n",
    "                                                         num_docs=docs_count, \n",
    "                                                         domain_specific_topics=np.arange(5), \n",
    "                                                         background_topics=np.arange(5, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "artm_model = artm.ARTM(topics_count, [sparse_smooth_reg], [1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter#1: loglike=-19353.851157493616\n",
      "iter#2: loglike=-18382.01480925508\n",
      "iter#3: loglike=-17084.132102431704\n",
      "iter#4: loglike=-15825.865801640357\n",
      "iter#5: loglike=-14911.744544324698\n",
      "iter#6: loglike=-14354.1965844772\n",
      "iter#7: loglike=-14023.507620175966\n",
      "iter#8: loglike=-13810.019306692513\n",
      "iter#9: loglike=-13671.359443310223\n",
      "iter#10: loglike=-13607.86162922442\n"
     ]
    }
   ],
   "source": [
    "train_result = artm_model.train(word_in_doc_freqs, words_list, iterations_count=10, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['4419', '3419', '4471', '9599', '4335', '9316', '3877', '2251',\n",
       "        '2721', '8255'],\n",
       "       ['7315', '1221', '165', '1562', '8809', '6870', '6213', '7160',\n",
       "        '3946', '6117'],\n",
       "       ['7268', '9809', '6538', '8889', '62', '75', '5145', '1851', '8216',\n",
       "        '2317'],\n",
       "       ['8527', '5346', '4690', '3863', '2352', '8948', '9392', '3041',\n",
       "        '2392', '6273'],\n",
       "       ['4648', '5830', '1004', '9483', '6559', '3275', '9299', '8246',\n",
       "        '3012', '3599'],\n",
       "       ['1950', '4545', '2003', '7627', '6687', '4922', '5249', '1981',\n",
       "        '2593', '178'],\n",
       "       ['3659', '4331', '7726', '8131', '6447', '6572', '7434', '7444',\n",
       "        '2597', '7233'],\n",
       "       ['1610', '493', '7762', '8146', '4300', '8837', '127', '4751',\n",
       "        '3317', '5703'],\n",
       "       ['2273', '2467', '5192', '9673', '5666', '8769', '5674', '3845',\n",
       "        '9987', '2742'],\n",
       "       ['7949', '4998', '876', '2654', '889', '1097', '8294', '2656',\n",
       "        '947', '3328']],\n",
       "      dtype='<U4')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_result.get_top_words_in_topics(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Covariance topics reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "covariance_regularizer = CovarianceTopicsRegularizer(tau=0.5, num_topics=topics_count, \n",
    "                                                     num_words=words_count, num_docs=docs_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "artm_model = artm.ARTM(topics_count, [covariance_regularizer], [1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter#1: loglike=-19364.56568899796\n",
      "iter#2: loglike=-18364.448409010456\n",
      "iter#3: loglike=-17026.670811239164\n",
      "iter#4: loglike=-15821.971973761776\n",
      "iter#5: loglike=-14962.085452076823\n",
      "iter#6: loglike=-14363.729678237405\n",
      "iter#7: loglike=-13994.68252844139\n",
      "iter#8: loglike=-13809.889967255864\n",
      "iter#9: loglike=-13699.14051890597\n",
      "iter#10: loglike=-13628.15489578\n"
     ]
    }
   ],
   "source": [
    "train_result = artm_model.train(word_in_doc_freqs, words_list, iterations_count=10, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['215', '7315', '5037', '4471', '9599', '3877', '5103', '9264',\n",
       "        '2251', '7726'],\n",
       "       ['2169', '2273', '1221', '6564', '3419', '2127', '2659', '3845',\n",
       "        '1820', '876'],\n",
       "       ['947', '1610', '3135', '3317', '8291', '5666', '2981', '3041',\n",
       "        '1614', '5192'],\n",
       "       ['1711', '1344', '9809', '1825', '4419', '6447', '3441', '2742',\n",
       "        '6337', '5703'],\n",
       "       ['7463', '80', '8216', '3275', '6128', '9987', '3963', '8246',\n",
       "        '7233', '4998'],\n",
       "       ['8924', '9392', '127', '7213', '4573', '6687', '2463', '1968',\n",
       "        '815', '9576'],\n",
       "       ['523', '6213', '3946', '3945', '5346', '4300', '4584', '4562',\n",
       "        '4814', '5249'],\n",
       "       ['6572', '3863', '7434', '8948', '5830', '5339', '3236', '41',\n",
       "        '3918', '7762'],\n",
       "       ['4922', '5145', '2721', '493', '178', '2582', '1071', '4751',\n",
       "        '7579', '2467'],\n",
       "       ['6703', '9299', '762', '6232', '4690', '7751', '1401', '1851',\n",
       "        '2392', '960']],\n",
       "      dtype='<U4')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_result.get_top_words_in_topics(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
