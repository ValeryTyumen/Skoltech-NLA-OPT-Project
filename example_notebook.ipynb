{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import artm\n",
    "from base_regularizer import BaseRegularizer\n",
    "from smoothing_regularizer import SmoothingRegularizer\n",
    "from combined_smoothing_sparsing_regularizer import CombinedSmoothingSparsingRegularizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_word_in_doc_freqs(words_count, docs_count):\n",
    "\n",
    "    density = 0.01\n",
    "    max_freq = 5\n",
    "\n",
    "    word_in_doc_freqs = sparse.dok_matrix((words_count, docs_count), dtype=int)\n",
    "\n",
    "    for i in range(int(density*words_count*docs_count)):\n",
    "\n",
    "        word_index = np.random.choice(words_count)\n",
    "        doc_index = np.random.choice(docs_count)\n",
    "\n",
    "        word_in_doc_freqs[word_index, doc_index] = np.random.choice(max_freq) + 1\n",
    "\n",
    "    return word_in_doc_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZeroRegularizer(BaseRegularizer):\n",
    "\n",
    "    def __init__(self, words_count, docs_count, topics_count):\n",
    "\n",
    "        self._word_in_topics_probs_grad = np.zeros((words_count, topics_count))\n",
    "        self._topic_in_doc_probs_grad = np.zeros((topics_count, docs_count))\n",
    "\n",
    "    def get_value(self, word_in_topics_probs, topic_in_doc_probs):\n",
    "\n",
    "        return 0.0\n",
    "\n",
    "    def get_gradient(self, word_in_topics_probs, topic_in_doc_probs):\n",
    "\n",
    "        return self._word_in_topics_probs_grad, self._topic_in_doc_probs_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed=0)\n",
    "\n",
    "words_count = 10000\n",
    "docs_count = 100\n",
    "topics_count = 10\n",
    "\n",
    "word_in_doc_freqs = generate_word_in_doc_freqs(words_count, docs_count)\n",
    "words_list = np.array([str(i) for i in range(words_count)])\n",
    "\n",
    "zero_regularizer = ZeroRegularizer(words_count, docs_count, topics_count)\n",
    "\n",
    "artm_model = artm.ARTM(topics_count, [zero_regularizer], [1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter#1: loglike=-253375.08594793238\n",
      "iter#2: loglike=-248155.68445356327\n",
      "iter#3: loglike=-240993.1539559364\n",
      "iter#4: loglike=-232894.0453807986\n",
      "iter#5: loglike=-225252.51292302719\n",
      "iter#6: loglike=-218928.3537355944\n",
      "iter#7: loglike=-214095.5894093739\n",
      "iter#8: loglike=-210671.68357721536\n",
      "iter#9: loglike=-208376.4824507103\n",
      "iter#10: loglike=-206869.89796774133\n"
     ]
    }
   ],
   "source": [
    "train_result = artm_model.train(word_in_doc_freqs, words_list, iterations_count=10, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['7326', '5398', '9117', '2136', '3057', '5825', '1747', '3845',\n",
       "        '1692', '7526'],\n",
       "       ['2824', '6332', '7097', '2735', '2789', '9496', '4471', '5995',\n",
       "        '902', '3957'],\n",
       "       ['9537', '7037', '2874', '9457', '1695', '2953', '3248', '367',\n",
       "        '3392', '6169'],\n",
       "       ['1632', '7464', '3708', '2460', '8019', '2522', '682', '8904',\n",
       "        '1609', '6327'],\n",
       "       ['3419', '1221', '6538', '5146', '8160', '4479', '621', '6762',\n",
       "        '9477', '2168'],\n",
       "       ['1100', '1273', '6923', '9966', '7853', '999', '4459', '3713',\n",
       "        '6223', '5479'],\n",
       "       ['4740', '3764', '1372', '5311', '5607', '4980', '7415', '1671',\n",
       "        '6583', '692'],\n",
       "       ['9098', '2755', '3996', '9536', '2010', '1564', '1265', '5865',\n",
       "        '4267', '3825'],\n",
       "       ['7932', '4186', '1004', '8174', '3555', '0', '8986', '6514',\n",
       "        '1983', '2003'],\n",
       "       ['2317', '1565', '9275', '8777', '5807', '6572', '2547', '5213',\n",
       "        '7543', '4420']],\n",
       "      dtype='<U4')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_result.get_top_words_in_topics(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smoothing reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothing_regularizer = SmoothingRegularizer(beta_0=0.5, alpha_0=0.5, \n",
    "                                             beta=np.array([1e-4]*words_count), \n",
    "                                             alpha=np.array([1e-4]*topics_count), \n",
    "                                             num_topics=topics_count, \n",
    "                                             num_words=words_count, \n",
    "                                             num_docs=docs_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "artm_model = artm.ARTM(topics_count, [smoothing_regularizer], [1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter#1: loglike=-253219.94032536348\n",
      "iter#2: loglike=-247916.4319508186\n",
      "iter#3: loglike=-240702.23933397373\n",
      "iter#4: loglike=-232505.00464822774\n",
      "iter#5: loglike=-224862.14859385107\n",
      "iter#6: loglike=-218885.28773205075\n",
      "iter#7: loglike=-214763.95457877737\n",
      "iter#8: loglike=-212025.89114727278\n",
      "iter#9: loglike=-210116.20784951735\n",
      "iter#10: loglike=-208688.23683997602\n"
     ]
    }
   ],
   "source": [
    "train_result = artm_model.train(word_in_doc_freqs, words_list, iterations_count=10, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining smooth and sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_smooth_reg = CombinedSmoothingSparsingRegularizer(beta_0=0.5, alpha_0=0.5, \n",
    "                                                         beta=np.array([1e-4]*words_count), \n",
    "                                                         alpha=np.array([1e-4]*topics_count), \n",
    "                                                         num_topics=topics_count, \n",
    "                                                         num_words=words_count, \n",
    "                                                         num_docs=docs_count, \n",
    "                                                         domain_specific_topics=np.arange(5), \n",
    "                                                         background_topics=np.arange(5, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "artm_model = artm.ARTM(topics_count, [sparse_smooth_reg], [1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter#1: loglike=-253372.61544487116\n",
      "iter#2: loglike=-248071.50356896667\n",
      "iter#3: loglike=-240742.03783599974\n",
      "iter#4: loglike=-232577.38516974295\n",
      "iter#5: loglike=-225318.40019621555\n",
      "iter#6: loglike=-219681.819856372\n",
      "iter#7: loglike=-215474.55468768373\n",
      "iter#8: loglike=-212378.0939240878\n",
      "iter#9: loglike=-210210.30299463565\n",
      "iter#10: loglike=-208686.06198959038\n"
     ]
    }
   ],
   "source": [
    "train_result = artm_model.train(word_in_doc_freqs, words_list, iterations_count=10, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['4728', '4895', '4634', '5339', '1221', '553', '8535', '1709',\n",
       "        '2126', '2953'],\n",
       "       ['2756', '8781', '6332', '5388', '1562', '7233', '6700', '2344',\n",
       "        '1175', '1350'],\n",
       "       ['2488', '7267', '4479', '8201', '9576', '3057', '1111', '4681',\n",
       "        '9457', '9181'],\n",
       "       ['1747', '9089', '6953', '4409', '5119', '8116', '6283', '1498',\n",
       "        '349', '6385'],\n",
       "       ['8741', '8315', '3323', '3918', '6337', '8809', '2546', '1115',\n",
       "        '2426', '8717'],\n",
       "       ['2977', '3923', '2736', '6572', '6679', '8517', '9191', '6624',\n",
       "        '4766', '3963'],\n",
       "       ['4922', '6054', '2208', '7642', '6583', '1206', '2', '3753',\n",
       "        '5713', '296'],\n",
       "       ['1208', '6458', '9076', '8897', '9098', '4028', '9718', '2641',\n",
       "        '6359', '9658'],\n",
       "       ['3091', '4600', '1291', '4950', '2714', '1609', '5758', '7521',\n",
       "        '1454', '2490'],\n",
       "       ['4963', '9908', '40', '8269', '7326', '3644', '420', '2558',\n",
       "        '2689', '7835']],\n",
       "      dtype='<U4')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_result.get_top_words_in_topics(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
